{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Topic Modeling & Classification. A case study for Novo Nordisk and Scientific Intelligence. All rights reserved. Carl Johanson, 2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b25f8-7d16-4404-a951-52ab477dd9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis.gensim\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import phrases\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gensim.models import HdpModel\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the translated dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b467fa-694b-412b-95cd-975c4e823214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the translated dataset\n",
    "df = pd.read_csv('/Users/carljohanson/Desktop/Speciale - Code Project/Code/Final/data/translated_text.csv')\n",
    "\n",
    "#show the shape of the dataset\n",
    "df.shape\n",
    "\n",
    "#show the dataset\n",
    "#df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Corpus preprocessing - First Round"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d6033-326d-41db-948f-f3650a7f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization of the clean and translated text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining a function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and \"'\" not in token and token not in string.punctuation]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "#apply the function to the translated text\n",
    "df['tokens_text'] = df['translated_text'].apply(preprocess_text)\n",
    "\n",
    "#show the tokens\n",
    "df['tokens_text'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Corpus preprocessing - Second Round"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d4097-ca2e-4d41-bb08-fd79ae2ca4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text with bigrams, trigrams\n",
    "# English\n",
    "connector_words = phrases.ENGLISH_CONNECTOR_WORDS\n",
    "\n",
    "# Detect bigrams\n",
    "bigram = Phrases(df['tokens_text'], min_count=5, threshold=100, connector_words=connector_words)\n",
    "bigram_phraser = Phraser(bigram)\n",
    "\n",
    "# Detect trigrams\n",
    "trigram = Phrases(bigram_phraser[df['tokens_text']], min_count=5, threshold=100, connector_words=connector_words)\n",
    "trigram_phraser = Phraser(trigram)\n",
    "\n",
    "#defining a function to preprocess the text with bigrams and trigrams\n",
    "def preprocess_text_bigram_trigram(tokens):\n",
    "\n",
    "    # Detect and add bigrams and trigrams\n",
    "    tokens = bigram_phraser[tokens]\n",
    "    tokens = trigram_phraser[tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "#apply the function to the translated text\n",
    "df['preprocessed_text'] = df['tokens_text'].apply(preprocess_text_bigram_trigram)\n",
    "\n",
    "#show the tokens\n",
    "df['preprocessed_text'].head(50)\n",
    "\n",
    "#show the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Corpus preprocessing - Third Round"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#remove rows with empty lists\n",
    "df = df[df.astype(str)['preprocessed_text'] != '[]']\n",
    "\n",
    "#remove rows with less than 5 words\n",
    "df = df[df['preprocessed_text'].map(len) > 5]\n",
    "\n",
    "#remove tokens with less than 3 characters\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(lambda x: [item for item in x if len(item) > 3])\n",
    "\n",
    "#show the shape of the dataset\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "148b6087",
   "metadata": {},
   "source": [
    "Visualize the word count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ca809",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#word count distribution\n",
    "#create a new column with number of words for each documents\n",
    "df[\"word_count\"] = df['preprocessed_text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "#visualize it\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df[\"word_count\"], bins=100)\n",
    "plt.title(\"Word Count Distribution\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.xticks(range(0, max(df[\"word_count\"]), 20))  # Adjust the range and step size as needed\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c14e85",
   "metadata": {},
   "source": [
    "Prepare a corpus and a dictionary using the preprocessed text for the HDP and LDA algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610c5b7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#create a list of list to mirror the structure of the preprocessed text data\n",
    "doc_list = df['preprocessed_text'].tolist()\n",
    "\n",
    "#create a dictionary from the preprocessed text data\n",
    "dictionary = corpora.Dictionary(doc_list)\n",
    "\n",
    "#convert the preprocessed text data into a bag-of-words representation\n",
    "corpus = [dictionary.doc2bow(doc) for doc in doc_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show the dictionary and the corpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print the dictionary\n",
    "print(dictionary)\n",
    "dictionary.token2id.items()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#show a portion of the corpus\n",
    "for item in corpus:\n",
    "    print(f'{item[0]}: {item[1]}', end=' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#word count ID\n",
    "word_counts = [[(dictionary[id], count) for id, count in line] for line in corpus]\n",
    "for item in word_counts:\n",
    "    print(f'{item[0]}: {item[1]}', end=' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The HDP algorithm determines the best amount of topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#store the inferred number of topics\n",
    "num_topics_list = []\n",
    "\n",
    "#run the HDP algorithm 20 times\n",
    "for i in range(20):\n",
    "    #randomly set the concentration parameters\n",
    "    alpha = random.uniform(0.1, 2)\n",
    "    gamma = random.uniform(0.1, 2)\n",
    "\n",
    "    #create an HDP model and train it\n",
    "    hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "\n",
    "    #get the number of topics inferred by the HDP model\n",
    "    num_topics = len(hdpmodel.show_topics())\n",
    "\n",
    "    #store the inferred number of topics\n",
    "    num_topics_list.append(num_topics)\n",
    "\n",
    "    #show the number of topics inferred by the HDP model\n",
    "    num_topics_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute the best number of topics by coherence value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Inspired by David Roepke from https://www.dataknowsall.com/topicmodels.html\n",
    "#compute coherence values for different numbers of topics\n",
    "limit = 100\n",
    "start = 5\n",
    "step = 5\n",
    "\n",
    "#store the inferred values\n",
    "coherence_values = []\n",
    "\n",
    "#run the LDA algorithm for different numbers of topics to detect optimal number of topics\n",
    "for num_topics in range(start, limit, step):\n",
    "    model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42)\n",
    "    coherence_model = CoherenceModel(model=model, texts=doc_list, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(coherence_model. get_coherence())\n",
    "\n",
    "#plot the coherence scores\n",
    "plt.figure(figsize=(10,8))\n",
    "x = range(start, limit, step)\n",
    "ax = sns.lineplot(x=x, y=coherence_values, color='#238C8C')\n",
    "plt.title(\"Best Number of Topics for LDA Model\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.xlim(start, limit)\n",
    "plt.xticks(range(2, limit, step))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute the optimal number of iterations for the LDA algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#set the number of topics and define the range of iterations\n",
    "iterations = range(10, 2000, 100)  # Adjust the range and step size as needed\n",
    "\n",
    "#store the inferred perplexity values\n",
    "perplexity_values = []\n",
    "for num_iterations in iterations:\n",
    "    model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=20, iterations=num_iterations, random_state=42)\n",
    "    perplexity_values.append(model.log_perplexity(corpus))\n",
    "\n",
    "#plot the perplexity scores\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(iterations, perplexity_values, color='#238C8C')\n",
    "plt.title(\"Perplexity for LDA Model\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='#238C8C', ls='-', label='Perplexity'),\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "9627026b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T13:12:58.830583Z",
     "start_time": "2023-04-30T13:11:20.683458Z"
    }
   },
   "source": [
    "The LDA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78aac9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#train the LDA model using the BoW vectors and the determined amount of topics\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=20, iterations=1010, alpha=\"auto\", eta=\"auto\", random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "#Save model to disk.\n",
    "temp_file = datapath(\"/Users/carljohanson/Desktop/Speciale - Code Project/Code/Models/lda_model\")\n",
    "lda_model.save(temp_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "69328986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T13:12:58.841682Z",
     "start_time": "2023-04-30T13:12:58.834123Z"
    }
   },
   "source": [
    "Visualize the results from the LDA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#visualise the word frequency in the topics\n",
    "for doc in corpus:\n",
    "   print([[dictionary[id], freq] for id, freq in doc])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print the keywords in all the topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get the top 15 words for each topic\n",
    "top_words_per_topic = []\n",
    "for topic_idx, topic in lda_model.show_topics(num_topics=18, num_words=15, formatted=False):\n",
    "    top_words = [word for word, _ in topic]\n",
    "    top_words_per_topic.append(top_words)\n",
    "\n",
    "    #print the output\n",
    "    formatted_top_words = \", \".join(top_words)\n",
    "    print(f\"Topic {topic_idx}: {formatted_top_words}\")\n",
    "\n",
    "#create a DataFrame with topics as columns\n",
    "topics_df = pd.DataFrame(top_words_per_topic).T\n",
    "topics_df.columns = \"topic_labels\"\n",
    "\n",
    "#print the DataFrame\n",
    "topics_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get the topic distribution for each document in the corpus\n",
    "topic_dist = [lda_model.get_document_topics(doc) for doc in corpus]\n",
    "\n",
    "#define the number of documents to sample per topic\n",
    "num_docs_per_topic = 5\n",
    "\n",
    "#sample a few documents from each topic based on their topic probabilities\n",
    "docs_per_topic = {}\n",
    "for i, dist in enumerate(topic_dist):\n",
    "    for topic, prob in dist:\n",
    "        if topic not in docs_per_topic:\n",
    "            docs_per_topic[topic] = []\n",
    "        docs_per_topic[topic].append((i, prob))\n",
    "\n",
    "for topic in range(lda_model.num_topics):\n",
    "    print(f\"\\nTopic {topic+1}:\\n\")\n",
    "    docs = sorted(docs_per_topic[topic], key=lambda x: x[1], reverse=True)[:num_docs_per_topic]\n",
    "    for doc_id, _ in docs:\n",
    "        print(df['preprocessed_text'][doc_id])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "beffa5ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T13:13:05.262834Z",
     "start_time": "2023-04-30T13:13:00.087084Z"
    }
   },
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get the baseline coherence score for the model (the average median). Hyperparameter tuning will change it.\n",
    "cm = CoherenceModel(model=lda_model, corpus=corpus, texts=doc_list, coherence='c_v')\n",
    "coherence_lda = cm.get_coherence()\n",
    "\n",
    "#print the coherence score\n",
    "print(coherence_lda)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#perplexity. The lower the better\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "5d8b2115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T13:13:13.107065Z",
     "start_time": "2023-04-30T13:13:06.496321Z"
    }
   },
   "source": [
    "Visualise distribution, relevance and most salient terms in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create the pyLDAvis visualisation\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "#display the visualisation\n",
    "vis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try clustering the documents to see similarity between documents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create a new vector representation of the documents to avoid confusion with the previous BoW representation\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "X = vectorizer.fit_transform(df[\"translated_text\"])\n",
    "\n",
    "#try different values for the number of clusters\n",
    "cluster_range = range(2, 30)\n",
    "silhouette_scores = []\n",
    "\n",
    "#document clustering using K-means and the vectorized documents\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Determine the optimal number of clusters based on silhouette scores\n",
    "optimal_k = cluster_range[silhouette_scores.index(max(silhouette_scores))]\n",
    "\n",
    "# Perform the clustering and assign cluster labels to the dataframe\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans.fit(X)\n",
    "df[\"cluster\"] = kmeans.labels_\n",
    "print(df[[\"preprocessed_text\", \"cluster\"]].head(10))\n",
    "\n",
    "# Count the number of documents in each cluster\n",
    "cluster_counts = df[\"cluster\"].value_counts().reset_index()\n",
    "cluster_counts.columns = [\"cluster\", \"count\"]\n",
    "\n",
    "# Visualize the document distribution by cluster\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(cluster_counts[\"cluster\"], cluster_counts[\"count\"])\n",
    "plt.title(\"Document Distribution by Cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Number of Documents\")\n",
    "plt.xticks(range(0, optimal_k))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#visualize the distribution of document clusters by similarity in a scatterplot\n",
    "tsne = TSNE(n_components=2, init=\"random\", random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "df[\"tsne_x\"] = X_tsne[:, 0]\n",
    "df[\"tsne_y\"] = X_tsne[:, 1]\n",
    "\n",
    "#plot the document clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(optimal_k):\n",
    "    cluster_data = df[df[\"cluster\"] == i]\n",
    "    plt.scatter(cluster_data[\"tsne_x\"], cluster_data[\"tsne_y\"], label=f\"Cluster {i}\", alpha=0.6)\n",
    "\n",
    "#add labels and legend\n",
    "plt.title(\"Document Clustering with t-SNE\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.legend()\n",
    "\n",
    "#display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "dfffd725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T13:14:39.792639Z",
     "start_time": "2023-04-30T13:14:38.357460Z"
    }
   },
   "source": [
    "Determine the best (dominant) topic of each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5ceb1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#loop through each document in the corpus and get its topic distribution\n",
    "topic_distributions = []\n",
    "for i, doc in enumerate(corpus):\n",
    "    topic_dist = lda_model.get_document_topics(doc, minimum_probability=0.0)\n",
    "    topic_distributions.append(topic_dist)\n",
    "\n",
    "#extract the dominant topic for each document and add it as a new column in the dataframe\n",
    "df['dominant_topic'] = [max(topic_dist, key=lambda x:x[1])[0] for topic_dist in topic_distributions]\n",
    "\n",
    "#display the topic distribution for the first document\n",
    "#print(topic_distributions[0])\n",
    "\n",
    "#display the dataframe\n",
    "#df[['description', 'dominant_topic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualise the distribution of dominant topics across the documents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#count the frequency of each dominant topic\n",
    "topic_counts = df[\"dominant_topic\"].value_counts().reset_index()\n",
    "topic_counts.columns = [\"topic\", \"count\"]\n",
    "\n",
    "#sort topics by their index\n",
    "topic_counts = topic_counts.sort_values(\"topic\")\n",
    "\n",
    "#plot the distribution of dominant topics across the documents\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(topic_counts[\"topic\"], topic_counts[\"count\"])\n",
    "plt.title(\"Document Distribution by Dominant Topic\")\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Number of Documents\")\n",
    "plt.xticks(range(0, len(topic_counts)))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#clustering documents based by their dominant topic value\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#reduce the dimensionality to 2D\n",
    "tsne = TSNE(n_components=2, init=\"random\", random_state=42)\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "#use a colormap to map topic values to colors\n",
    "plt.figure(figsize=(14, 8))\n",
    "cmap = cm.get_cmap(\"viridis\", np.unique(df[\"dominant_topic\"]).size)\n",
    "\n",
    "for topic in np.unique(df[\"dominant_topic\"]):\n",
    "    mask = df[\"dominant_topic\"] == topic\n",
    "    plt.scatter(X_2d[mask, 0], X_2d[mask, 1], c=[cmap(topic)], label=f\"Topic {topic}\")\n",
    "\n",
    "#display the plot and add labels\n",
    "plt.title(\"Scatter plot of documents by dominant topic\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "213767bf",
   "metadata": {},
   "source": [
    "Prepare for the ML classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4378c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#export topic proportions and labels to ML classifier\n",
    "\n",
    "#compute the topic proportions for each document in the corpus\n",
    "topic_proportions = []\n",
    "for doc in corpus:\n",
    "    topic_vector = lda_model.get_document_topics(doc, minimum_probability=0.0)\n",
    "    proportions = [topic_prob[1] for topic_prob in topic_vector]\n",
    "    topic_proportions.append(proportions)\n",
    "\n",
    "#add topic proportions to the dataframe\n",
    "df['topic_proportions'] = topic_proportions\n",
    "\n",
    "#show the column\n",
    "#df['topic_proportions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21ba65",
   "metadata": {},
   "source": [
    "#Correcting a visual error in datalab from using PyLDAvis\n",
    "\n",
    "from IPython.display import HTML\n",
    "css_str = '<style> \\\n",
    ".jp-Button path { fill: #616161;} \\\n",
    "text.terms { fill: #616161;} \\\n",
    ".jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    ".bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    ".jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "text.terms { fill: #616161;} \\\n",
    "</style>'\n",
    "display(HTML(css_str ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b6dea",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd45f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#extract feature vectors and labels from the DataFrame\n",
    "X = np.array(df['topic_proportions'].tolist())  #features (document-topic distributions)\n",
    "y = df['dominant_topic'].values  #labels (categories/classes)\n",
    "\n",
    "#display the shapes of X and y\n",
    "#X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a4ef3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#split the dataset 80:20 for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#print the shapes of the training and testing sets\n",
    "#X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "#display the training set\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing all classifiers at once using the lazypredict library to determine the best"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fit all models\n",
    "all_clf = LazyClassifier(predictions=True, random_state=42)\n",
    "models, predictions = all_clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#print model performance metrics (accuracy and training time), full list of models sorted\n",
    "#from highest to lowest accuracy and model prediction results\n",
    "models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#detect the best parameters for the Random Forest Classifier using GridSearchCV\n",
    "#define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4, 5, 6, 7, 8, 10, 15, 20, 30, 40, 50],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#create a base model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                           cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "#fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#get the best parameters\n",
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train the Random Forest Classifier with the best parameters\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=40, max_features='sqrt', criterion='gini', random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#predict the test set\n",
    "y_pred = rf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Compute the F1-score of the classifier\n",
    "f1 = f1_score(y_test, predictions, average='weighted')  # or 'macro'/'micro', depending on your task\n",
    "print(f\"F1-Score: {f1}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the random forest model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#save the random forest model\n",
    "import joblib\n",
    "joblib.dump(rf, '/Users/carljohanson/Desktop/Speciale - Code Project/Code/Models/rf_model', compress=9)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
