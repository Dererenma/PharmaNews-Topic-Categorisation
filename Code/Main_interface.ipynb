{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nbconvert import PythonExporter\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the topic model and topic classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only run once. It trains and creates the models and saves them to disk. Store somewhere else after running. The models will then be saved in the Models directory for future runs. There is no need to run this again, except if you want to retrain the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_notebook(notebook_path):\n",
    "    with open(notebook_path) as nb_file:\n",
    "        notebook = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "    python_exporter = PythonExporter()\n",
    "    python_source, _ = python_exporter.from_notebook_node(notebook)\n",
    "\n",
    "    exec(python_source, globals())\n",
    "\n",
    "#The #0 notebook is the one that retrieves data. I have extracted a sample already for use. The dataset is called final_MEMO_data.csv\n",
    "\n",
    "#The other two notebooks are the ones that preprocess the data and train the models. They are called #1_corpus_preprocessing.ipynb and #2_Topic_Modelling_&_Classifier.ipynb\n",
    "\n",
    "#only run the #0 notebook once. It will extract the data from the InfoDesk API and save it to disk. The other two notebooks can be run as many times as you want to retrain the models.\n",
    "\n",
    "notebook_paths = [ #'#0_extract_data_from_infodesk.ipynb'\n",
    "                  '/Users/carljohanson/Desktop/Speciale - Code Project/Code/Backend-Code/#1_corpus_preprocessing.ipynb',\n",
    "                  '/Users/carljohanson/Desktop/Speciale - Code Project/Code/Backend-Code/#2_Topic_Modelling_&_Classifier.ipynb']\n",
    "\n",
    "for path in notebook_paths:\n",
    "    run_notebook(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classify the daily MEMO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determine the time period to extract the data from and export in into the extracter. This will be the last 24 hours. Change at will"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#get the current time\n",
    "now = datetime.utcnow()\n",
    "\n",
    "#get 24 hours before now\n",
    "twenty_four_hours_ago = now - timedelta(days=1)\n",
    "\n",
    "#convert to the required format\n",
    "end_date = now.strftime(\"%Y-%m-%dT%H:%M:%S.701Z\") # End date is current time\n",
    "start_date = twenty_four_hours_ago.strftime(\"%Y-%m-%dT%H:%M:%S.701Z\") # Start date is 24 hours ago\n",
    "\n",
    "#your data\n",
    "data = {\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": end_date\n",
    "}\n",
    "\n",
    "#write to a JSON file into the same directory\n",
    "with open('data/dates.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change the profiles for retrieving the new MEMO. Change once, and then run the extracter, repeat until finished"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "profiles = 'zojw' #adjust to change profiles\n",
    "\n",
    "#'clxj', 'nk93', 'tuc3', 'qkfq', 'duvj', 'uctf', 'u0vc', 'ggnd', 'xb2m', 'dofq', '4hwz', '5ls8', 'klhg', 'jmnc', 'kvkg', 'hj7v', 'xfdy', '9cxo', 'jeh2', 'zojw'\n",
    "\n",
    "#your data\n",
    "data = {\n",
    "    \"profiles\": profiles,\n",
    "}\n",
    "\n",
    "#write to a JSON file into the same directory\n",
    "with open('data/profiles.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the daily batch memo text from the database using the InfoDesk API.\n",
    "Right now there is no way to get all profiles at once. The profiles are extracted one by one and then concatenated into one dataframe. This is a manual process done above. Repeat until all profiles are extracted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_notebook(notebook_path):\n",
    "    with open(notebook_path) as nb_file:\n",
    "        notebook = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "    python_exporter = PythonExporter()\n",
    "    python_source, _ = python_exporter.from_notebook_node(notebook)\n",
    "\n",
    "    exec(python_source, globals())\n",
    "\n",
    "notebook_paths = ['/Users/carljohanson/Desktop/Speciale - Code Project/Code/Backend-Code/#3_get_new_memo_articles_from_infodesk.ipynb']\n",
    "\n",
    "for path in notebook_paths:\n",
    "    run_notebook(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate the JSON files into one dataframe for preprocessing. First done after all profiles have been extracted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_notebook(notebook_path):\n",
    "    with open(notebook_path) as nb_file:\n",
    "        notebook = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "    python_exporter = PythonExporter()\n",
    "    python_source, _ = python_exporter.from_notebook_node(notebook)\n",
    "\n",
    "    exec(python_source, globals())\n",
    "\n",
    "notebook_paths = ['/Users/carljohanson/Desktop/Speciale - Code Project/Code/Backend-Code/#4_concatenate_JSON_files.ipynb']\n",
    "\n",
    "for path in notebook_paths:\n",
    "    run_notebook(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text pre-process the new MEMO data and categorise the articles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_notebook(notebook_path):\n",
    "    with open(notebook_path) as nb_file:\n",
    "        notebook = nbformat.read(nb_file, as_version=4)\n",
    "\n",
    "    python_exporter = PythonExporter()\n",
    "    python_source, _ = python_exporter.from_notebook_node(notebook)\n",
    "\n",
    "    exec(python_source, globals())\n",
    "\n",
    "notebook_paths = ['/Users/carljohanson/Desktop/Speciale - Code Project/Code/Backend-Code/#5_preprocess_new_memo.ipynb']\n",
    "\n",
    "for path in notebook_paths:\n",
    "    run_notebook(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The daily and classified MEMO ready for use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load the new memo with the categorised articles\n",
    "new_memo = pd.read_csv('/Users/carljohanson/Desktop/Speciale - Code Project/Code/Results/prepared_memo.csv')\n",
    "\n",
    "new_memo"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
